# -*- coding: utf-8 -*-
"""Submission_Predictive_Analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hbn9tLpuMy2eUS8KJn7li0hgoGZfYVyZ

# **Predictive Analytics Gemstone Price**

Nama: Febri Isthifa Adha

Email: febriadha136@gmail.com

# **1. Import library**
"""

# Commented out IPython magic to ensure Python compatibility.
# mengimpor pustaka yang diperlukan
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns
import zipfile
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

"""# **2. Data Loading**

Data Loading merupakan tahap untuk memuat dataset yang akan digunakan agar dataset lebih mudah dipahami.

Dataset yang digunakan pada proyek ini:

https://www.kaggle.com/datasets/dhanrajcodes/gemstone-price
"""

# Upload kaggle.json
from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}"'.format(name=fn))

# Ubah permission file
!chmod 600 /content/kaggle.json

# Download dataset
!kaggle datasets download -d dhanrajcodes/gemstone-price

# Tentukan path ke file ZIP
zip_path = zipfile.ZipFile('/content/gemstone-price.zip', 'r')
zip_path.extractall('/content/')
zip_path.close()

"""# **3. Data Understanding**

Menampilkan isi dataset yang ada di `gemstone.csv`.
"""

gemstone = pd.read_csv('/content/gemstone.csv')
gemstone

"""Menghapus kolom pertama yang berisikan nomor masing-masing data (id)."""

gemstone.drop("id",axis=1,inplace=True)

"""## **3.1 Exploratory Data Analysis**

Exploratory data analysis (EDA) merupakan proses investigasi awal pada data untuk menganalisis karakteristik, menemukan pola, anomali, dan memeriksa asumsi pada data.

### **3.1.1 Deskripsi Variabel**
"""

gemstone.info()

"""Dari hasil di atas, terlihat bahwa kolom `cut`, `color`, `clarity` bertipe object, kolom `carat`, `depth`, `table`, `x`, `y`, `z` bertipe float64, dan kolom `price` bertipe int64.

Berikut merupakan arti dari masing-masing variabel beserta nilai-nilainya.

Variabel | Keterangan | Nilai
----------|----------|----------
id | Identifier unik untuk setiap batu permata |  1, 2, 3
carat | Berat batu permata dalam satuan karat |  0.2 - 5.01
cut | Kualitas potongan batu permata | Fair, Good, Very Good, Premium, Ideal
color | Warna batu permata | D, E, F, G, H, I, J (D best)
clarity | Tingkat kejernihan batu permata | I1, SI2, SI1, VS2, VS1, VVS2, VVS1, IF (IF best)
depth | Total kedalaman dalam persentase | 43.0 - 79.0
table | Lebar bagian atas batu permata relatif terhadap titik terlebar | 43.0 - 95.0
x | Panjang batu permata dalam mm |  0.0 - 10.74
y | Lebar batu permata dalam mm | 0.0 - 58.9
price | Harga batu permata dalam (USD) | 326 - 18,823

### **3.1.2 Deskripsi Statistik Data**

Selanjutnya, kita akan melihat deskripsi statistik dari data yang dimiliki.
"""

gemstone.describe()

"""Fungsi `describe()` memberikan informasi statistik pada masing-masing kolom, antara lain:

- `Count` adalah jumlah sampel pada data.
- `Mean` adalah nilai rata-rata.
- `Std` adalah standar deviasi.
- `Min` yaitu nilai minimum setiap kolom.
- `25%` adalah kuartil pertama. Kuartil adalah nilai yang menandai batas interval dalam empat bagian sebaran yang sama.
- `50%` adalah kuartil kedua, atau biasa juga disebut median (nilai tengah).
- `75%` adalah kuartil ketiga.
- `Max` adalah nilai maksimum.

### **3.1.3 Menangani Missing Value**

Pertama, kita akan memeriksa apakah ada nilai 0 pada kolom `x`, `y`, `z`.
"""

x = (gemstone.x == 0).sum()
y = (gemstone.y == 0).sum()
z = (gemstone.z == 0).sum()

print("Nilai 0 di kolom x ada: ", x)
print("Nilai 0 di kolom y ada: ", y)
print("Nilai 0 di kolom z ada: ", z)

"""Terlihat bahwa ada beberapa nilai di kolom `x`, `y`, dan `z` yang bernilai 0. Kita akan memeriksa baris dari nilai-nilai 0 tersebut."""

gemstone.loc[(gemstone["z"] == 0)]

"""Terlihat bahwa pada untuk `z` bernilai 0, ternyata juga terdapat seluruh nilai 0 pada kolom `x` dan `y`. Oleh karena itu, baris-baris ini akan dihapus."""

# Menghapus baris dengan nilai "x", "y", dan "z" = 0
gemstone = gemstone.loc[(gemstone[["x", "y", "z"]] != 0).all(axis = 1)]

# Memeriksa ukuran data yang telah dihapus beberapa barisnya
gemstone.shape

"""Melakukan pengecekan ulang untuk missing value menggunakan `describe()`."""

gemstone.describe()

"""### **3.1.4 Memeriksa Data Duplikat**"""

# Menghitung jumlah baris yang duplikat dalam Dataset
jumlah_duplikat = gemstone.duplicated().sum()
print("\nJumlah Duplikat:", jumlah_duplikat)

"""Terlihat bahwa tidak ada data duplikat pada dataset.

### **3.1.5 Memeriksa Outlier**

Outliers merupakan sampel yang nilainya sangat jauh dari cakupan umum data utama, dengan itu kita akan memeriksa apakah terdapat outlier pada kolom-kolom numerik.
"""

# Pilih hanya kolom numerik
numeric_columns = gemstone.select_dtypes(include=["number"]).columns

# Mengatur dimensi plot
plt.figure(figsize=(15, 8))

# Buat boxplot untuk setiap kolom numerik
for i, column in enumerate(numeric_columns, 1):
    plt.subplot(2, 4, i)
    sns.boxplot(data=gemstone, y=column, color="steelblue")
    plt.title(f'{column}')
    plt.ylabel(column)

plt.tight_layout()
plt.show()

"""Berdasarkan output diagram di atas terlihat bahwa ada outliers pada fitur carat, depth, table, price, x, y, dan z. Pada kasus ini, kita akan menghapus outlier menggunakan teknik Inter Quartile Range (IQR). IQR didefinisikan sebagai :


IQR = Inter Quartile Range

IQR = Q3 - Q1

"""

# Hitung Q1, Q3, dan IQR hanya untuk kolom numerik
Q1 = gemstone[numeric_columns].quantile(0.25)
Q3 = gemstone[numeric_columns].quantile(0.75)
IQR = Q3 - Q1

# Filter DataFrame berdasarkan IQR
gemstone = gemstone[~((gemstone[numeric_columns] < (Q1 - 1.5 * IQR)) |
                    (gemstone[numeric_columns] > (Q3 + 1.5 * IQR))).any(axis = 1)]

gemstone.shape

"""Jumlah Datasets setalah kita hapus Outlier: `168755, 10`

### **3.1.6 Univariate Analysis**

Membagi fitur pada dataset menjadi dua bagian, yaitu numerical features dan categorical features.
"""

# Membagi kolom-kolom menjadi kolom numerikal dan kolom kategorikal
numerical_features = ["price", "carat", "depth", "table", "x", "y", "z"]
categorical_features = ["cut", "color", "clarity"]

"""### a. Categorical Features"""

# Memeriksa Fitur Cut
feature = categorical_features[0]
count_cut = gemstone[feature].value_counts()
percent = 100 * gemstone[feature].value_counts(normalize = True)
df_cut = pd.DataFrame({"jumlah sampel" : count_cut, "persentase" : percent.round(1)})
print(df_cut)
count_cut.plot(kind = "bar", title = feature)

"""Terdapat 5 kategori pada fitur Cut, secara berurutan dari jumlahnya yang paling banyak yaitu: Ideal, Premium, Very Good, Good, dan Fair. Dari data persentase dapat kita simpulkan bahwa lebih dari 70% sampel merupakan gemstone tipe grade tinggi, yaitu grade Ideal dan Premium."""

# Memeriksa Fitur Cut
feature = categorical_features[1]
count_color = gemstone[feature].value_counts()
percent = 100 * gemstone[feature].value_counts(normalize = True)
df_color = pd.DataFrame({"jumlah sampel" : count_color, "persentase" : percent.round(1)})
print(df_color)
count_color.plot(kind = "bar", title = feature)

"""Terdapat urutan kategori warna dari yang paling buruk hingga yang paling bagus adalah J, I, H, G, F, E, dan D. Dari grafik di atas, dapat disimpulkan bahwa sebagian besar grade berada pada grade menengah, yaitu G, F, H."""

# Memeriksa Fitur Cut
feature = categorical_features[2]
count_clarity = gemstone[feature].value_counts()
percent = 100 * gemstone[feature].value_counts(normalize = True)
df_clarity = pd.DataFrame({"jumlah sampel" : count_clarity, "persentase" : percent.round(1)})
print(df_clarity)
count_clarity.plot(kind = "bar", title = feature)

"""Terdapat fitur Clarity terdiri dari 8 kategori dari yang paling buruk ke yang paling baik, yaitu: I1, SI2, SI1, VS2, VS1, VVS2, VVS1, dan IF. Dari grafik dapat disimpulkan bahwa sebagian besar fitur merupakan grade rendah, yaitu SI1, SI2, dan VS2.

### b. Numerical Features

Pada tiap fitur numerik akan membuat visualisasi dengan histogram sebagai berikut:
"""

gemstone.hist(bins=50, figsize=(20,15))
plt.show()

"""Berdasarkan grafik histogram di atas, dapat disimpulkan sebagai berikut:

- Pada fitur carat menunjukkan histogram right-skewed.
- Pada fitur depth menunjukkan histogram zero-skewed atau simetris/normal.
- Pada fitur table menunjukkan histogram right-skewed.
- Pada fitur price menunjukkan histogram right-skewed.
- Peningkatan harga gemstone sebanding dengan penurunan jumlah sampel.

### **3.1.7 Multivariate Analysis**

### a. Categorical Features

Mengecek rata-rata harga terhadap masing-masing fitur kategori yaitu cut, color dan clarity untuk mengetahui pengaruh fitur tersebut terhadap harga.
"""

cat_features = gemstone.select_dtypes(include="object").columns.to_list()

for col in cat_features:
    sns.catplot(x=col, y="price", hue=col, kind="bar", dodge=False, height=4,
                aspect=3, data=gemstone, palette="Set3", legend=False)
    plt.title("Rata-rata 'price' Relatif terhadap - {}".format(col))
    plt.show()

"""b. Numerical Features

Mengecek rata-rata harga terhadap masing-masing fitur numerik yaitu carat, depth, table, x, y, dan z untuk mengetahui pengaruh fitur tersebut terhadap harga.
"""

# Mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(gemstone, diag_kind = 'kde')

"""### **3.1.8 Correlation Matrik**

Pengecekan korelasi atau hubungan antar fitur numerik menggunakan heatmap correlation matrix.
"""

plt.figure(figsize = (10, 8))
correlation_matrix = gemstone[numerical_features].corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot = True
sns.heatmap(data = correlation_matrix, annot = True, cmap = "Blues", linewidths = 0.5)
plt.title("Correlation Matrix untuk Fitur Numerik")

"""Berdasarkan diagram heatmap di atas, fitur 'carat', 'x', 'y', dan 'z' memiliki skor korelasi yang besar (diatas 0.9) dengan fitur target 'price'. Dimana, fitur 'price' berkolerasi tinggi dengan keempat fitur tersebut. Sementara fitur 'depth' memiliki korelasi yang sangat kecil (0.05). Sehingga fitur 'depth' dapat dihapus.

Menghapus fitur depth pada dataset karena memiliki korelasi yang rendah terhadap fitur price.
"""

gemstone.drop(['depth'], inplace=True, axis=1)
gemstone.head()

"""# **4. Data Preparation**

Pada tahap persiapan data atau data preparation dilakukan beberapa proses, yaitu encoding pada fitur kategori, reduksi dimensi dengan menggunakan Principal Component Analysis (PCA), Train Test Split, dan proses standarisasi data.

## **4.1 Encoding Fitur Kategori**

Melakukan proses encoding pada fitur kategori cut, color, dan clarity.
"""

# Encoding Fitur Kategori
gemstone = pd.concat([gemstone, pd.get_dummies(gemstone["cut"], prefix = "cut")],axis = 1)
gemstone = pd.concat([gemstone, pd.get_dummies(gemstone["color"], prefix = "color")],axis = 1)
gemstone = pd.concat([gemstone, pd.get_dummies(gemstone["clarity"], prefix = "clarity")],axis = 1)
gemstone.drop(["cut", "color", "clarity"], axis = 1, inplace = True)
gemstone.head()

"""## **4.2 Reduksi Dimensi dengan PCA**

Melakukan pengecekan pada fitur ukuran gemstone yaitu fitur x, y, dan z.
"""

# Reduksi Dimensi dengan PCA
sns.pairplot(gemstone[["x", "y", "z"]], plot_kws = {"s": 3});

from sklearn.decomposition import PCA

pca = PCA(n_components = 3, random_state = 123)
pca.fit(gemstone[["x", "y", "z"]])
princ_comp = pca.transform(gemstone[["x", "y", "z"]])

"""Mendapatkan proporsi informasi dari ketiga komponen yaitu x, y, dan z."""

pca.explained_variance_ratio_.round(3)

"""Membuat fitur baru untuk menggantikan fitur x, y, dan z yaitu dimension."""

pca = PCA(n_components = 1, random_state = 123)
pca.fit(gemstone[["x", "y", "z"]])
gemstone["dimension"] = pca.transform(gemstone.loc[:,  ("x", "y", "z")]).flatten()
gemstone.drop(["x", "y", "z"], axis = 1, inplace = True)

"""## **4.3 Train Test Split**

Membagian dataset akan menggunakan proporsi pembagian 90:10 dengan fungsi train_test_split dari sklearn.
"""

# Train-Test-Split
X = gemstone.drop(["price"],axis = 1)
y = gemstone["price"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 123)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""## **4.4 Standarisasi**

StandardScaler dapat dirumuskan sebagai
$$z = \frac{x-u}{s}$$
dengan
* $z$: Nilai data setelah distandarisasi
* $x$: Nilai data sebelum distandarisasi
* $u$: Nilai rata-rata keseluruhan data
* $s$: Nilai standar deviasi data
"""

from sklearn.preprocessing import StandardScaler

# Standarisasi
numerical_features = ["carat", "table", "dimension"]
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

X_train[numerical_features].describe().round(4)

"""Dapat dilihat bahwa setelah proses standarisasi sekarang nilai mean = 0 dan standar deviasi = 1.

# **5. Model Development**

Mempersiapkan dataframe untuk menganalisis ketiga model yang akan digunakan yaitu K-Nearest Neighbor, Random Forest, Gradient Boosting.
"""

from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import GridSearchCV

# Siapkan dataframe untuk analisis model
models = pd.DataFrame(index = ["train_mse", "test_mse"],
                      columns = ["KNN", "RandomForest", "Boosting"])

"""## **7.1 Model K-Nearest Neighbor**

K-Nearest Neighbors (KNN) adalah algoritma machine learning yang sederhana dan mudah dipahami untuk klasifikasi dan regresi. Algoritma ini bekerja dengan menemukan k tetangga terdekat dari data baru dan kemudian menggunakan kategori atau nilai rata-rata dari tetangga tersebut untuk memprediksi kategori atau nilai data baru.
"""

knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(X_train, y_train)
models.loc["train_mse","knn"] = mean_squared_error(y_pred = knn.predict(X_train), y_true = y_train)

"""## **7.2 Model Random Forest**

Random Forest adalah algoritma machine learning ensemble yang menggabungkan beberapa decision tree untuk meningkatkan akurasi prediksi. Algoritma ini bekerja dengan membuat banyak decision tree secara acak dan kemudian menggunakan voting untuk memprediksi kategori atau nilai data baru.
"""

RF = RandomForestRegressor(n_estimators = 50, max_depth = 10, random_state = 55, n_jobs = -1)
RF.fit(X_train, y_train)
models.loc["train_mse", "RandomForest"] = mean_squared_error(y_pred = RF.predict(X_train), y_true = y_train)

"""## **7.3 Model Gradient Boosting**

Gradient Boosting adalah algoritma machine learning yang menggunakan teknik ensembel learning dari decision tree untuk memprediksi nilai. Gradient Boosting sangat mampu menangani pattern yang kompleks dan data ketika linear model tidak dapat menangani.
"""

boosting = GradientBoostingRegressor(max_depth=7, random_state=55)
boosting.fit(X_train, y_train)
models.loc["train_mse", "Boosting"] = mean_squared_error(y_pred = boosting.predict(X_train), y_true = y_train)

"""# **8. Evaluasi Model**

Melakukan proses scaling fitur numerik pada data uji agar skala antara data latih dan data uji sama.
"""

# Lakukan scaling terhadap fitur numerik pada X_test sehingga memiliki rata-rata = 0 dan varians = 1
X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

"""Untuk evaluasi, kita akan menggunakan *Mean Squared Error* (MSE). MSE dirumuskan sebagai :
$$MSE = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2$$

Keteranga :
* $N$: Jumlah data
* $y_i$: Nilai y sesungguhnya
* $\hat{y_i}$: Nilai y prediksi

"""

# Buat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada masing-masing algoritma
mse = pd.DataFrame(columns = ["train", "test"], index = ["KNN", "RF", "Boosting"])

# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {"KNN": knn, "RF": RF, "Boosting": boosting}

for name, model in model_dict.items():
    mse.loc[name, "train"] = mean_squared_error(y_true = y_train, y_pred = model.predict(X_train))/1e3
    mse.loc[name, "test"] = mean_squared_error(y_true = y_test, y_pred = model.predict(X_test))/1e3

mse

fig, ax = plt.subplots()
mse.sort_values(by = "test", ascending = False).plot(kind = "barh", ax = ax, zorder = 3)
ax.grid(zorder = 0)

"""Berdasarkan grafik di atas, dapat disimpulkan sebagai berikut:

- Model dengan Gradient Boosting memberikan nilai error yang paling besar yaitu train sebesar 133.044841 dan test sebesar 146.840974.
- Model dengan algoritma KKN memberikan nilai error train sebesar 158.060099 dan test sebesar 188.027968.
- Model dengan algoritma Random Forest memberikan nilai error yang paling kecil yaitu train sebesar 184.881839 dan test sebesar 189.772913.
"""

prediksi = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)

"""Terlihat bahwa prediksi model KNN, prediksi model RF, dan prediksi model Bossting adalah 994, 701, dan 915 dari y_true 868. Dari ketiga model, model yang memiliki nilai prediksi meleset sangat kecil adalah model Boosting dan model yang memiliki nilai prediksi meleset sangat besar adalah RF."""